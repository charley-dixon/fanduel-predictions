{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Assembly DSI - Denver 2018\n",
    "## Capstone Project - DFS Model\n",
    "This is my capstone project at General Assembly's fifth [Data Science Immersive](https://generalassemb.ly/education/data-science-immersive) cohort in 2018. I am developing a model to assist in optimizing NFL lineups on the daily fantasy sports platforms [Draft Kings](https://www.draftkings.com/) and [Fan Duel](https://www.fanduel.com/).\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Can we build a model to predict a football player’s fantasy football performance to estimate their value and implement the model in conjunction with a daily fantasy strategy to be profitable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/charleydixon/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv('../data/modeling_qbs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby(['Name', 'Year', 'Week', 'Month', 'Team', 'Oppt']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>h/a</th>\n",
       "      <th>Favored</th>\n",
       "      <th>Spread</th>\n",
       "      <th>O/U</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Weather_DOME</th>\n",
       "      <th>Weather_Fog</th>\n",
       "      <th>Weather_Rain</th>\n",
       "      <th>...</th>\n",
       "      <th>Y/A</th>\n",
       "      <th>Yards</th>\n",
       "      <th>Opp_Avg_Att_Allowed</th>\n",
       "      <th>Opp_Avg_Comp_Allowed</th>\n",
       "      <th>Opp_Avg_Ints</th>\n",
       "      <th>Opp_Rank</th>\n",
       "      <th>Opp_Avg_TDs_Allowed</th>\n",
       "      <th>Opp_Avg_Yds_Allowed</th>\n",
       "      <th>FD salary</th>\n",
       "      <th>FD points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Week</th>\n",
       "      <th>Month</th>\n",
       "      <th>Team</th>\n",
       "      <th>Oppt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Barkley, Matt</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2013</th>\n",
       "      <th>8</th>\n",
       "      <th>October</th>\n",
       "      <th>PHI</th>\n",
       "      <th>NYG</th>\n",
       "      <td>23.049</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>49.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.450000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>47.333333</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>November</th>\n",
       "      <th>PHI</th>\n",
       "      <th>OAK</th>\n",
       "      <td>23.056</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.265000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>278.666667</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2016</th>\n",
       "      <th>12</th>\n",
       "      <th>November</th>\n",
       "      <th>CHI</th>\n",
       "      <th>TEN</th>\n",
       "      <td>26.080</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>255.666667</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>22.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>December</th>\n",
       "      <th>CHI</th>\n",
       "      <th>SF</th>\n",
       "      <td>26.087</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.625000</td>\n",
       "      <td>198.500000</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>19.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>30</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>7.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>December</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DET</th>\n",
       "      <td>26.094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>42.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.306667</td>\n",
       "      <td>196.333333</td>\n",
       "      <td>24.666667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>12.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Age  h/a  Favored  Spread  \\\n",
       "Name          Year Week Month    Team Oppt                                 \n",
       "Barkley, Matt 2013 8    October  PHI  NYG   23.049    1        1    -5.5   \n",
       "                   9    November PHI  OAK   23.056    0        0    -1.0   \n",
       "              2016 12   November CHI  TEN   26.080    1        0    -6.5   \n",
       "                   13   December CHI  SF    26.087    1        0    -1.0   \n",
       "                   14   December CHI  DET   26.094    0        0    -7.5   \n",
       "\n",
       "                                             O/U  Temperature  Wind  \\\n",
       "Name          Year Week Month    Team Oppt                            \n",
       "Barkley, Matt 2013 8    October  PHI  NYG   49.5         58.0  13.0   \n",
       "                   9    November PHI  OAK   45.5         62.0   6.0   \n",
       "              2016 12   November CHI  TEN   42.0         38.0   5.0   \n",
       "                   13   December CHI  SF    44.0         35.0   5.0   \n",
       "                   14   December CHI  DET   42.0         72.0   0.0   \n",
       "\n",
       "                                            Weather_DOME  Weather_Fog  \\\n",
       "Name          Year Week Month    Team Oppt                              \n",
       "Barkley, Matt 2013 8    October  PHI  NYG              0            0   \n",
       "                   9    November PHI  OAK              0            0   \n",
       "              2016 12   November CHI  TEN              0            1   \n",
       "                   13   December CHI  SF               0            0   \n",
       "                   14   December CHI  DET              1            0   \n",
       "\n",
       "                                            Weather_Rain    ...           Y/A  \\\n",
       "Name          Year Week Month    Team Oppt                  ...                 \n",
       "Barkley, Matt 2013 8    October  PHI  NYG              0    ...      6.450000   \n",
       "                   9    November PHI  OAK              0    ...      6.265000   \n",
       "              2016 12   November CHI  TEN              0    ...      5.400000   \n",
       "                   13   December CHI  SF               1    ...      5.625000   \n",
       "                   14   December CHI  DET              0    ...      7.306667   \n",
       "\n",
       "                                                 Yards  Opp_Avg_Att_Allowed  \\\n",
       "Name          Year Week Month    Team Oppt                                    \n",
       "Barkley, Matt 2013 8    October  PHI  NYG   129.000000            47.333333   \n",
       "                   9    November PHI  OAK   143.500000            43.000000   \n",
       "              2016 12   November CHI  TEN    81.000000            35.333333   \n",
       "                   13   December CHI  SF    198.500000            30.666667   \n",
       "                   14   December CHI  DET   196.333333            24.666667   \n",
       "\n",
       "                                            Opp_Avg_Comp_Allowed  \\\n",
       "Name          Year Week Month    Team Oppt                         \n",
       "Barkley, Matt 2013 8    October  PHI  NYG              26.000000   \n",
       "                   9    November PHI  OAK              26.333333   \n",
       "              2016 12   November CHI  TEN              22.333333   \n",
       "                   13   December CHI  SF               19.666667   \n",
       "                   14   December CHI  DET              13.666667   \n",
       "\n",
       "                                            Opp_Avg_Ints  Opp_Rank  \\\n",
       "Name          Year Week Month    Team Oppt                           \n",
       "Barkley, Matt 2013 8    October  PHI  NYG       2.000000        19   \n",
       "                   9    November PHI  OAK       1.000000        10   \n",
       "              2016 12   November CHI  TEN       0.333333         8   \n",
       "                   13   December CHI  SF        0.333333        30   \n",
       "                   14   December CHI  DET       0.000000         9   \n",
       "\n",
       "                                            Opp_Avg_TDs_Allowed  \\\n",
       "Name          Year Week Month    Team Oppt                        \n",
       "Barkley, Matt 2013 8    October  PHI  NYG              1.666667   \n",
       "                   9    November PHI  OAK              1.000000   \n",
       "              2016 12   November CHI  TEN              1.666667   \n",
       "                   13   December CHI  SF               2.000000   \n",
       "                   14   December CHI  DET              1.333333   \n",
       "\n",
       "                                            Opp_Avg_Yds_Allowed  FD salary  \\\n",
       "Name          Year Week Month    Team Oppt                                   \n",
       "Barkley, Matt 2013 8    October  PHI  NYG            308.000000     5800.0   \n",
       "                   9    November PHI  OAK            278.666667     6000.0   \n",
       "              2016 12   November CHI  TEN            255.666667     6000.0   \n",
       "                   13   December CHI  SF             255.000000     6000.0   \n",
       "                   14   December CHI  DET            164.000000     6200.0   \n",
       "\n",
       "                                            FD points  \n",
       "Name          Year Week Month    Team Oppt             \n",
       "Barkley, Matt 2013 8    October  PHI  NYG        3.32  \n",
       "                   9    November PHI  OAK        0.32  \n",
       "              2016 12   November CHI  TEN       22.64  \n",
       "                   13   December CHI  SF         7.98  \n",
       "                   14   December CHI  DET       12.48  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- Linear Regression\n",
    "- Random Forest\n",
    "- Support Vector Regression\n",
    "- Boosting\n",
    "- PCA\n",
    "- Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============EVAULATION=============\n",
      "\n",
      "R2 Training: 0.15486610055413175\n",
      "R2 Testing: 0.18665600551619443\n",
      "RMSE: 7.287011116864119\n",
      "MAE: 5.843886835718315 \n",
      "\n",
      "=============COEFFICIENTS=============\n",
      "\n",
      "Intercept: -0.20327927495129572\n",
      "Age -0.06140023478284524\n",
      "h/a 1.0642877383415745\n",
      "Favored 1.0974248609121435\n",
      "Spread 0.051009312296253044\n",
      "O/U 0.0733439606349433\n",
      "Temperature 0.00872591655260506\n",
      "Wind -0.07066066594197369\n",
      "Weather_DOME -0.7921370031943825\n",
      "Weather_Fog 0.7450121526853518\n",
      "Weather_Rain -0.873967921546931\n",
      "Weather_Rain | Fog -6.012113835360802\n",
      "Weather_Snow -0.5201543654175679\n",
      "Weather_Snow | Fog -0.8148385738626248\n",
      "Weather_Snow | Freezing Rain 8.316867116125255\n",
      "Weather_Sunny -0.048667569419144095\n",
      "Attempts 0.034780555734668234\n",
      "Completions 0.13222211872378642\n",
      "Interceptions -0.47793441368624884\n",
      "Rating 0.0061988000776445305\n",
      "TDs 0.14102747930959597\n",
      "Y/A 0.14235124384640124\n",
      "Yards -0.0054605595972012835\n",
      "Opp_Avg_Att_Allowed -0.017740374245161485\n",
      "Opp_Avg_Comp_Allowed -0.029322777943181378\n",
      "Opp_Avg_Ints 0.016947429866321313\n",
      "Opp_Rank -0.12229781729889888\n",
      "Opp_Avg_TDs_Allowed -0.3550030456055616\n",
      "Opp_Avg_Yds_Allowed 0.0031793698086185246\n",
      "FD salary 0.0017651550948144315\n"
     ]
    }
   ],
   "source": [
    "columns = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "def linreg(df, features, target = 'FD points'):\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n",
    "\n",
    "    # first attempt - all features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('=============EVAULATION=============\\n')\n",
    "    print('R2 Training:', model.score(X_train, y_train))\n",
    "    print('R2 Testing:', model.score(X_test, y_test))\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    print('RMSE:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "    print('MAE:', mean_absolute_error(y_test, predictions), '\\n')\n",
    "    print('=============COEFFICIENTS=============\\n')\n",
    "    print('Intercept:', model.intercept_)\n",
    "    for key, index in dict(zip(X.columns, model.coef_)).items():\n",
    "        print(key, index)\n",
    "    return model\n",
    "\n",
    "lr_all_features = linreg(data, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that seem logical:\n",
    "- Increasing Prediction for:\n",
    "    - Home/Away\n",
    "    - Favored\n",
    "    - O/U\n",
    "    - Attempts\n",
    "    - Completions\n",
    "    - TDs\n",
    "    - Y/A\n",
    "    \n",
    "- Decreasing Prediction for:\n",
    "    - Age\n",
    "        - Sort of...\n",
    "    - Wind\n",
    "    - Rain\n",
    "    - Rain & Fog\n",
    "    - Snow\n",
    "    - Snow & Fog\n",
    "    - Interceptions\n",
    "    - Opponent Rank\n",
    "        - The rank columns is actually backwards so defenses get better as ranking improves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Coefficients that make no sense to me:\n",
    "- Increasing Prediction for:\n",
    "    - Fog\n",
    "    - Snow & Freezing Rain\n",
    "    - Opponent Interceptions\n",
    "- Decreasing Prediction for:\n",
    "    - Being in a Dome (Controlled conditions seem like a player should perform better)\n",
    "    - Sunny weather\n",
    "    - Yards\n",
    "    - Opponent Attempts Allowed\n",
    "    - Opponent Completions Allowed\n",
    "    - Opponent TDs Allowed\n",
    "- Almost no effect from:\n",
    "    - Rating\n",
    "    - FD Salary\n",
    "        - Considering salary kind of derives FanDuel's predictions I feel like this would have an impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The most interesting thing to note here is that FD Salary has seemingly no effect on a player's point production**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'h/a', 'Favored', 'Spread', 'O/U', 'Temperature', 'Wind',\n",
       "       'Weather_DOME', 'Weather_Fog', 'Weather_Rain', 'Weather_Rain | Fog',\n",
       "       'Weather_Snow', 'Weather_Snow | Fog', 'Weather_Snow | Freezing Rain',\n",
       "       'Weather_Sunny', 'Attempts', 'Completions', 'Interceptions', 'Rating',\n",
       "       'TDs', 'Y/A', 'Yards', 'Opp_Avg_Att_Allowed', 'Opp_Avg_Comp_Allowed',\n",
       "       'Opp_Avg_Ints', 'Opp_Rank', 'Opp_Avg_TDs_Allowed',\n",
       "       'Opp_Avg_Yds_Allowed', 'FD salary', 'FD points'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = ['Weather_Fog', 'Weather_Snow | Freezing Rain', 'Opp_Avg_Ints', 'Weather_DOME', \n",
    "               'Weather_Sunny', 'Yards', 'Opp_Avg_Att_Allowed', 'Opp_Avg_Comp_Allowed', \n",
    "               'Opp_Avg_TDs_Allowed', 'Rating', 'FD salary', 'FD points']\n",
    "\n",
    "features = [col for col in data.columns if col not in remove_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============EVAULATION=============\n",
      "\n",
      "R2 Training: 0.12384088048260056\n",
      "R2 Testing: 0.12012426937208964\n",
      "RMSE: 7.579193053472293\n",
      "MAE: 6.021901659335721 \n",
      "\n",
      "=============COEFFICIENTS=============\n",
      "\n",
      "Intercept: 3.3717179304861666\n",
      "Age -0.05184342532900565\n",
      "h/a 0.7545127193585466\n",
      "Favored 2.082204448223854\n",
      "Spread 0.04722141450700851\n",
      "O/U 0.21074076440789036\n",
      "Temperature -0.002075301163649467\n",
      "Wind -0.052021627297039484\n",
      "Weather_Rain -0.8217764014883531\n",
      "Weather_Rain | Fog -5.562976552428371\n",
      "Weather_Snow -0.8758091619729306\n",
      "Weather_Snow | Fog 0.47061620156574135\n",
      "Attempts 0.07961798927262871\n",
      "Completions 0.11265372081012745\n",
      "Interceptions -0.7045880819602188\n",
      "TDs 0.854891438318532\n",
      "Y/A 0.2526735741740987\n",
      "Opp_Rank -0.11165553997398336\n",
      "Opp_Avg_Yds_Allowed -0.0060759040342483256\n"
     ]
    }
   ],
   "source": [
    "lr_partial_features = linreg(data, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04326462235328713"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "cross_val_score(model, X_train, y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07804748959279184"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.141268456375839"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.758300116519505"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [10, 20, 30], 'n_estimators': [70, 75, 80], 'min_samples_leaf': [13, 14], 'max_features': [10, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "params = {\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'n_estimators': [70, 75, 80],\n",
    "    'min_samples_leaf': [13, 14],\n",
    "    'max_features': [10, 20]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13994090141689752\n",
      "0.18205143193102846\n",
      "{'max_depth': 10, 'max_features': 10, 'min_samples_leaf': 13, 'n_estimators': 70}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.867280408469351\n",
      "7.326354429216604\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0.04732571806887254,\n",
       " 'h/a': 0.011567405036229763,\n",
       " 'Favored': 0.01860889460390169,\n",
       " 'Spread': 0.04428143039214601,\n",
       " 'O/U': 0.05569674677120847,\n",
       " 'Temperature': 0.028938038789831845,\n",
       " 'Wind': 0.023075553027321654,\n",
       " 'Weather_DOME': 0.0025294271001848633,\n",
       " 'Weather_Fog': 0.0,\n",
       " 'Weather_Rain': 0.0,\n",
       " 'Weather_Rain | Fog': 0.0,\n",
       " 'Weather_Snow': 0.0,\n",
       " 'Weather_Snow | Fog': 0.0,\n",
       " 'Weather_Snow | Freezing Rain': 0.0,\n",
       " 'Weather_Sunny': 0.002947863117521723,\n",
       " 'Attempts': 0.04965422647524838,\n",
       " 'Completions': 0.05979835822322462,\n",
       " 'Interceptions': 0.014529852306577636,\n",
       " 'Rating': 0.055703018520107894,\n",
       " 'TDs': 0.0329191301008596,\n",
       " 'Y/A': 0.04432541857952866,\n",
       " 'Yards': 0.0845525357638508,\n",
       " 'Opp_Avg_Att_Allowed': 0.03356653538207762,\n",
       " 'Opp_Avg_Comp_Allowed': 0.02498466504672492,\n",
       " 'Opp_Avg_Ints': 0.013748808397962222,\n",
       " 'Opp_Rank': 0.07658739522154372,\n",
       " 'Opp_Avg_TDs_Allowed': 0.017288672841565718,\n",
       " 'Opp_Avg_Yds_Allowed': 0.045644747490440854,\n",
       " 'FD salary': 0.21172555874306878}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(X.columns, gs.best_estimator_.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now this is telling me that `FD Salary` is far and away the most important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17839379011055656"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0035552533895411016"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.516993357999584"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'kernel': ['linear'], 'C': [0.1, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR()\n",
    "params = {\n",
    "    'kernel': ['linear'],\n",
    "    'C': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11735567863893763\n",
      "0.18523738880463558\n",
      "{'C': 0.01, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.820359894682846\n",
      "7.293363270531602\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADA Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [45, 47, 50], 'learning_rate': [0.8, 0.83, 0.85, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "params = {\n",
    "    'n_estimators': [45, 47, 50],\n",
    "    'learning_rate': [.8, .83, .85, .9]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08877834225084463\n",
      "0.11381732505308828\n",
      "{'learning_rate': 0.83, 'n_estimators': 45}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.19816261998654\n",
      "7.606308356372341\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [75, 80, 85], 'learning_rate': [0.15, 0.2, 0.25, 0.3]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingRegressor()\n",
    "params = {\n",
    "    'n_estimators': [75, 80, 85],\n",
    "    'learning_rate': [0.15, 0.2, 0.25, 0.3]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid=params)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08341984965942152\n",
      "0.15906787487379648\n",
      "{'learning_rate': 0.15, 'n_estimators': 80}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.score(X_test, y_test))\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.93891294315364\n",
      "7.409566015594872\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "print(mean_absolute_error(y_test, y_pred))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=24, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 24)\n",
    "pca.fit(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  [0.15884208 0.09447997 0.08122668 0.07204716 0.04974341 0.04485379\n",
      " 0.04019799 0.03860966 0.03725892 0.03546763 0.03508014 0.0347573\n",
      " 0.03381769 0.03137285 0.02975884 0.02751775 0.02423443 0.02357858\n",
      " 0.02324518 0.02216546 0.01599642 0.01521103 0.01107703 0.00908408]\n"
     ]
    }
   ],
   "source": [
    "var_exp = pca.explained_variance_ratio_\n",
    "print('Explained Variance: ', var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative Explained Variance:  [0.15884208 0.25332206 0.33454874 0.4065959  0.45633931 0.5011931\n",
      " 0.54139109 0.58000075 0.61725967 0.6527273  0.68780744 0.72256474\n",
      " 0.75638243 0.78775528 0.81751412 0.84503188 0.8692663  0.89284489\n",
      " 0.91609006 0.93825553 0.95425195 0.96946298 0.98054    0.98962408]\n"
     ]
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('Cumulative Explained Variance: ', cum_var_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train = pca.transform(X_train_scaled)\n",
    "Z_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1540178668111044\n",
      "0.18498667830864635\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(Z_train, y_train)\n",
    "print(model.score(Z_train, y_train))\n",
    "print(model.score(Z_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.850796686201867"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.294485304149663"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in data.columns if col != 'FD points']\n",
    "\n",
    "X = data[features]\n",
    "y = data['FD points']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(29, activation = 'relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dense(5, activation = 'relu'))\n",
    "model.add(Dense(1, activation=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1786 samples, validate on 596 samples\n",
      "Epoch 1/10\n",
      "1786/1786 [==============================] - 1s 558us/step - loss: 112.5548 - val_loss: 62.6327\n",
      "Epoch 2/10\n",
      "1786/1786 [==============================] - 1s 446us/step - loss: 59.4284 - val_loss: 59.0524\n",
      "Epoch 3/10\n",
      "1786/1786 [==============================] - 1s 441us/step - loss: 56.3815 - val_loss: 58.4015\n",
      "Epoch 4/10\n",
      "1786/1786 [==============================] - 1s 457us/step - loss: 54.6936 - val_loss: 60.8855\n",
      "Epoch 5/10\n",
      "1786/1786 [==============================] - 1s 459us/step - loss: 53.4761 - val_loss: 56.2386\n",
      "Epoch 6/10\n",
      "1786/1786 [==============================] - 1s 442us/step - loss: 52.2327 - val_loss: 58.3069\n",
      "Epoch 7/10\n",
      "1786/1786 [==============================] - 1s 437us/step - loss: 51.5675 - val_loss: 56.3714\n",
      "Epoch 8/10\n",
      "1786/1786 [==============================] - 1s 439us/step - loss: 51.0345 - val_loss: 56.6261\n",
      "Epoch 9/10\n",
      "1786/1786 [==============================] - 1s 450us/step - loss: 49.9332 - val_loss: 56.1545\n",
      "Epoch 10/10\n",
      "1786/1786 [==============================] - 1s 427us/step - loss: 50.0794 - val_loss: 57.0035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2a3137f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, \n",
    "          y_train, \n",
    "          epochs = 10, \n",
    "          batch_size = 2, \n",
    "          validation_data = (X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.081302643030282\n",
      "7.550065296454414\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test, predictions))\n",
    "print(np.sqrt(mean_squared_error(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
